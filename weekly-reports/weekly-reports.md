# Sara Zaki's Weekly Reports

## Week 16 (12/07 - 12/14)



## Week 15 (11/30 - 12/07)

The phrase 'living at Jacobs Hall' might have been an understatement for this week! Our team's dedication was unparalleled, with every challenge encountered adding to our excitement rather than our stress. We dug deep into the technicalities, solving every puzzle that came our way. From adapting to broken 'share' functions to pivoting to OpenAI’s API (which we had to pay for ಥ_ಥ), it was a week filled with rapid adaptation and learning.

The support and understanding within our team have been incredible. We've backed each other up through other class deadlines, ensuring no one fell behind. My role in AI and poetry integration was both challenging and rewarding. It was a thrill to push the boundaries of my technical skills, even if it meant resorting to glasses due to excessive screen time!

Our journey with Particle Photon2, ZeroWidth, OpenAI, Adafruit’s accelerometer, p5.js and Node.js was an odyssey of innovation and flexibility. Though not without its hurdles, the experience enriched our technical expertise. Despite some sacrifices in other assignments, the dedication to this project was unwavering. It was a testament to prioritization and focusing on what truly matters.

| | |
|:-------------------------:|:-------------------------:|
|<img width="1604" alt="Test 1 with p5.js" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/1b65bb29-5b1f-412f-8406-b0bdbbf2adf8"> |  <img width="1604" alt="Test 2 wiith Node.js" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/f75eb814-6f9a-4538-979b-d2f44422cf89"> |

### Speculations:

The culmination of our hard work in these final days has been nothing short of exhilarating. Our team’s resilience, creativity, and mutual support have been the keystones of this journey. As we prepare for the Jacobs Winter Showcase, there's a palpable excitement to share our creation with the world and gather feedback for future enhancements. My spidey senses tell me this is going to be AWESOME!!!

## Week 14 (11/23 - 11/30)

This week, our team dived deep into the intricate aspects of our project. It's been a journey of meticulous planning and execution, ensuring that every little detail aligns with our vision for the interactive art installation. Kudos to Jeff for his impromptu assistance in task delegation. His guidance was crucial in helping us step out of our comfort zones and embrace new challenges. The team's willingness to explore and collaborate has been outstanding, especially considering this is our first project together.

This is what our initial feasibility experiments looked like:
Bob - server configuration: configure with relevant libraries, test basic functions
Sara - accelerometer processing and translation to strings
Junjie - working on poetry experiments in zerowidth - structuring knowledge, eval what it means to generate poetry (consult with Sara)

Tasks:
Bob - share knowledge you have about micro-electronics with Sara via some meetings and examples
Sara - share knowledge regarding ways to think about poetry for the LLM; structuring information, suggested methods to execute, and what to look for in the evaluation of a quality response
Junjie - help Bob understand what you have been researching, how it relates to the tasks at hand, and what he might be working on that integrates with your research

I had a fantastic time introducing Junjie to the world of poetry and AI. We embarked on creating a new intelligence on ZeroWidth, an exciting venture into collaborative learning and innovation. Encountered a hiccup with the 'share' functions on ZeroWidth, but thankfully, Peter was our tech superhero, swooping in to resolve the issue promptly. On another front, while attempting to assist Bob with Node.js installation, we collectively decided to pivot to p5js. It proved to be a more straightforward and equally educational choice for us.
<img width="996" alt="Workflow ideation with Jeff" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/08bdddf2-9cdf-4da9-a051-1120245fa452">
Screenshot from workflow ideation and ideal task delegation meeting with Jeff ✔

### Speculations:

With the foundational work nearly complete, I'm curious to see how our project will evolve in the coming weeks. There's a sense of anticipation as we inch closer to realizing our collective vision. The diversity of skills and knowledge within our team hints at an exciting journey ahead. I speculate that our project will not only be a showcase of technical proficiency but also of personal and collective growth. The highlight of this week was undoubtedly the seamless collaboration and the eagerness of each team member to learn and adapt. The synergy within the team has been remarkable, and I'm incredibly proud of what we've achieved so far. Moving forward, we aim to build upon the solid foundation we've established. Whether it's exploring new technologies or refining our existing ideas, the goal is to keep the momentum going and steer our project towards a successful completion.

## Week 13 (11/16 - 11/23)
This week, my final project team (Junjie and Bob) has been nothing short of phenomenal. The level of communication, support, and commitment from each member has truly exceeded my expectations. It's heartening to see our collective enthusiasm in turning our interactive art installation from a concept to reality. Our check-ins with the instructional team were highly productive. These sessions provided us with much-needed clarity and direction, ensuring we stay on the right track.

The week was marked by intensive research and preliminary testing, all carried out in the spirit of close collaboration. It's impressive how seamlessly our team works together, each bringing unique insights and skills to the table.

Ah, Thanksgiving! It offered a much-needed pause in our busy schedules. While we didn't accomplish as much as planned work-wise, the break was a welcome respite. Personally, I found this time crucial for a 'hard reset,' recharging my batteries and returning with renewed vigor.

### Speculations:
Post-Thanksgiving, I anticipate a surge in our productivity. The rest has rejuvenated us, and I'm excited to see how this refreshed energy translates into our project work. Our art installation is beginning to take shape, and I speculate that the coming weeks will be filled with rapid development and creative breakthroughs. There's a buzzing sense of anticipation about how our project will evolve.

## Week 12 (11/09 - 11/16)

Exciting news! This week marked the formation of our dynamic trio for Project 4 – an interactive art installation. After the proposal poster showcase in class, I teamed up with Bob and Junjie, both of whom bring brilliant ideas and skills to the table. Originally, I had planned to embark on this project solo, envisioning it as a canvas for my personal creativity. However, I'm now thrilled at the prospect of turning it into a testament to the power of collaboration and teamwork.

Not gonna lie, this week was a rollercoaster of emotions. Amidst the chaos of final projects, deadlines, and pressure, I experienced several intense moments of stress. But fear not, I'm still hanging on! These experiences, while challenging, are teaching me the importance of resilience and self-care in high-pressure environments. While the week didn't offer much in terms of team collaboration due to lecture schedules, the formation of our team itself was a significant step. I'm eager to dive into more collaborative efforts as we progress with the project.

![TDF 4 Pin-up board](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/cded8778-fd37-4337-a476-2db8df27a271)


### Speculations:

As we embark on this journey, I'm curious about how our individual styles and ideas will mesh and evolve into something unique. The interactive nature of our art installation promises a blend of technology and creativity that I believe will captivate our audience. I'm quite optimistic about the direction our project will take. There's a buzzing excitement about what we can achieve as a team, and I'm speculating that our combined effort will result in a product that's not only innovative but also a true reflection of our shared vision.

The formation of a new team, coupled with the excitement and challenges of starting our final project, made this week memorable. Despite the emotional ups and downs, the anticipation of what's to come is truly exhilarating. As we move forward, I look forward to deepening our collaboration, refining our ideas, and starting the hands-on work. There's a lot to do, but with Bob and Junjie by my side, I'm confident that we're going to create something extraordinary.

## Week 11 (11/02 - 11/09)

Great week! I found a lot of inspiration in the guest lecture on Monday, by Mohit Bhoite on electronic and art. What truly resonated with me, among the many interesting things he said, was that there doesn't have to be a point to creating something and that he just does it because it brings him joy. Now I want to do something that brings ME joy - but I don't know what it is yet. 

Here are some of Mohit's devices:

| | | |
|:-------------------------:|:-------------------------:|:-------------------------:|
|<img width="1604" alt="Photon" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/efa83f4c-983a-4765-94d6-4e57d4d00f3f"> |  <img width="1604" alt="Another Photon" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/a17b8ee1-f9a9-4a75-a7aa-a446bf60099d"> |<img width="1604" alt="Yet Another Photon" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/1b67e37f-260c-4989-ab7d-71298182340d"> |

### Speculations:

My cohort seemed to really enjoy the guest lecture, too, and everyone seems excited about the freedom of choice which project 4 allows. I have spoken to a few of my classmates and from the many ideas I've heard, I think it is safe to say that we will be seeing some pretty awesome products at the end of the semester. Can't wait! This week, as there was no project to work on, I don't have much to say, but I believe that will change from this point onwards as we all get immersed in bringing our new ideas to life and delivering (what we all hope to be) an unforgettable, portfolio-worthy final project. Thank you.

## Week 10 (10/26 - 11/02)

Highlight of the week - I got sick and had to stay home from school for a few days :( I wear a mask ALL THE TIME! I don't know how I managed to get sick. Anyway...

We've all had a really productive week, getting deep into making our LLM 'mini-me's. Watching everyone, I was struck by how each person's creation was so different and personal. Some were particularly imaginative, taking the project in their own direction that really showed their enthusiasm.

For me, it was a busy but rewarding week. I managed to finish both parts of the AI 'mini-me' project before Tuesday. The first part was just as the project outlined, but the second part was more personal. I made it to help me share something important with my parents. It took a lot of testing and tweaking to get it right, but I’m happy with how it turned out.

| | | |
|:-------------------------:|:-------------------------:|:-------------------------:|
|<img width="1604" alt="No Privacy" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/2d08a8b3-0d26-44a1-9c7e-fe8277346c38">  Mini-Me Trying to Spill the Beans |  <img width="1604" alt="Generation Error" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/841b0278-21d1-4f11-8842-4d4de56f0a13"> Token Limit at 'Hi' |<img width="1604" alt="Token Limit" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/9348d79b-c82f-4ff0-9689-ec3ad81ac4b0"> Error Details |

I did run into some issues, though. Initially, my AI was giving out personal info to users due to inadequately structured instructions. After a few iterations, I was able to get it working as expected but then I ran into another problem - my context window was used up at just "hi." (the very beginning of the conversation). This issue led me to experiment with different models, transitioning from GPT-4 to GPT-3.5 Turbo 16k, which solved the token limit problem but brought a new challenge to the table, as the AI completely stopped inquiring about the user's identity at the beginning of the conversation. After several reiterations in the instructions and testing for hours, I finally figured out the most optimal way to train the model with explicit instructions and went back to the GPT-4. It was working much better. I also realized something interesting - the LLM couldn't tell the time correctly. LOL.

Playing with the AI's settings was fascinating, too. I learned that changing the temperature settings could make the AI's responses either straight to the point (with a low temp) or more creative (with a higher temp). Sure, I messed up a few times and broke the model several times, but I learned a lot from those mistakes and now I'm a little wiser than when I started - that is all that matters :) Another curious aspect of my experiments was understanding the impact of token count and context length on response time, which varied notably between models. This, I noticed, was crucial for optimizing the Mini-Me's performance.

| | | | |
|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|
|<img width="1604" alt="As a Student" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/8b165539-699b-4efb-aee2-6f7c8ead3d5d">  As a Student |  <img width="1604" alt="As an Instructor" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/ce381c53-442e-4359-928b-0f8a54ebeda3"> As an Instructor |<img width="1604" alt="As a Recruiter" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/8b8296ee-501b-41db-8cfb-fc00177403f1"> As a "Recrui ter" |<img width="1604" alt="As an Imposter" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/fa1df34f-7288-4804-868e-82749c1236b9"> As an Impostor (º～º) |

The key to making it all work was organizing the data well so the AI could use it correctly. Getting to that point took a lot of careful work. To say the least, handling the Knowledge Base was quite tough, as the AI kept hallucinating and spouting absolutely untrue, misleading garbage. Weirdly enough, each time I tested it and it failed, I just got more hyped up about fixing it because I took it on as a challenge - one from which I was determined to emerge victorious, at any cost. Using Retrieval Augmented Generation, I was able to efficiently structure and organize my knowledge base such that the LLM could pull only the necessary information and provide the appropriate response to the questions asked by the user.

### Speculations:

The week's endeavors led me to deep reflections on the future of AI. I see the potential for personalized digital companions to revolutionize our interactions with AI, providing tailored experiences that reflect individual human needs. For people in similar situations to mine, this technology offers a new way to navigate complex personal conversations. The process of creating my AI mini-me has been equivalent to capturing a digital essence of myself, a notion that feels like a step towards digital immortality. Considering the broader implications, I envision these technologies eventually evolving into platforms for personalized storytelling and support, TRANScending (pun intended) their current roles and revolutionizing human-machine interaction. Conclusively, this week has not only advanced my technical skills but also expanded my understanding of the emotional and practical capacities of AI. The blend of design, empathy, and technology is paving the way for exciting future applications that I am eager to explore further, beyond the scopes of this project.


## Week 9 (10/19 - 10/26)

Last week felt like sprinting through a storm of tasks and milestones, but we managed to complete our group project. Finally decided on a name - we called it the 'Rescue Ring.' It required some rapid-fire problem-solving and true grit, but our project landed across the finish line right on schedule. It was hardly a straightforward trip; we had our fair share of complex challenges and close calls that really put our determination to the test. It's during these rollercoaster moments that you get to know what a team is really made of. I’m honestly so grateful for the hard work and smarts everyone brought to the table — my team was fantastic and worked well together.

On a side note, during one of Peter’s lectures, I noticed a classmate who sat next to me, Junjie, seemed to be grappling with the new concepts. I took a moment to clarify things, which helped her catch up and simultaneously solidified my own understanding.

An intriguing thought hit me post-lecture: I’m now pondering over a personal project, employing AI I'm developing to convey a significant message to my parents (creating a mini-me that would help me come out to them). It’s an independent endeavor, yet the thought of merging my personal narrative with technology is quite thrilling. I think the next project is going to be so much fun!

Now we’ve shifted into a quieter week, which feels like a much-needed interlude. It's giving us some space to unwind and refocus, a chance to refresh our minds and stimulate our creativity for what comes next. Many thanks to the TDF instructional team.

Here's a link to the presentation video: [Rescue Ring](https://youtu.be/FSZ16t8Mt8I)


### Speculations:

Moving forward, I anticipate the convergence of personal storytelling with technology becoming a more prominent theme in design. Tools like ZeroWidth will likely gain importance, not only for their technical applications but for their potential in personal expression. As for my personal journey, I am excited at the prospect of exploring how these tools can enhance communication and self-expression. I anticipate that my exploration into ZeroWidth will not just be a learning experience but a stepping stone to incorporating more of my personal narrative into my design work.


## Week 8 (10/12 - 10/19)

I received a haptic controller from Jeff this week and soldered (for the first time). I had some trouble flashing my code to get the vibrating motor working, so I renamed the device from 'Enigmatic Photon 2 / P2s' (which was apparently too long and caused issues), to just 'Enigmatic' such that it was easier to work with.
![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/d9329e0a-8279-4771-ba92-670e45187acc)

After many, many tries and hours of debugging, I successfully flashed the code to my Photon2.
![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/e44411b0-7628-43ee-9bec-3e9284ab16d9)

https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/86fc8f16-3874-4560-91d9-cd8ddf498f52

My team was incredible this week. Everyone made great contributions, and we all helped each other learn and grow through this project. I am grateful for the help I received from everyone on my team - Eliza taught me to solder, Liam helped me set up my breadboard correctly and Vidit helped me get the Photon to Photon comms working. I couldn't have done this without them :) 

And this was by far the busiest week I've had this semester. I was simultaneously working on 6 different projects and each day was a deadline. I'm extremely proud of my efforts and output this week because I was able to get most of my work done (and in good quality) in time. I learned by doing, which I believe is the best method of learning. I had a lot of trouble compiling my code and flashing it to the Photon2. I even had to rename my device to get it work at some point. After that, my VScode completely stopped working so I had to switch to the Particle Web IDE and to my surprise, I was able to successfully compile and flash my code there. After that, the rest was a breeze. I helped test the connection between Photons with Vidit all night and it felt great that everything was working as planned.

### Speculations

For this project, we anticipate developing a tool that seamlessly integrates into users' daily lives, becoming an essential feature for enhancing personal safety across various social scenarios. Imagine being able to tap a button on your phone or smartwatch and instantly letting a friend know you need help, without making it obvious to anyone else. We're thinking about adding this to apps people already use, like texting or maybe even as a smartwatch feature. Of course, we know privacy is a big deal, so we'd make sure any alerts are super secure. Down the line, we might add more cool features, like sharing your location or even a way to contact emergency services. The key is to make it simple and quick to use, so people actually use it. If we get this right, we think it could really change the game for personal safety.

Presentation Video: [Link](https://youtu.be/FSZ16t8Mt8I)



## Week 7 (10/05 - 10/12)

This week, my team and I finalized our project topic. We had many great ideas but were finally able to settle on one, thanks to the feedback from every member of the instructional team. The idea we chose was a device that could be used in a social setting where if a person feels uncomfortable during a conversation, they can discreetly activate a "safe word" feature. This sends a subtle alert to a designated friend's device, signaling that they need assistance or an exit strategy. As an introvert, I'm very excited about this project as it could prove very helpful to those who find social interactions daunting. 

### Speculations
The development of this device has led us to explore multiple design tools and frameworks that can help realize the product's potential. Considering the fast-paced evolution of technology, particularly in the realm of IoT (Internet of Things) and wearable tech, I foresee these tools evolving significantly in the near future. The "safe word" feature could be activated via voice command, which requires advanced voice recognition software. With improvements in NLP (Natural Language Processing), future versions of our device may recognize not just a predetermined word but also context and tone of speech to provide even more accurate alerts. Given the sensitive nature of the device, robust security features are essential. I anticipate that there will be more focus on blockchain or similar decentralized technologies to secure user data. Also, as 5G becomes mainstream, devices like ours could utilize the high-speed, low-latency capabilities to provide real-time updates and more efficient alert systems.

As social awareness about issues like consent and personal safety grows, I believe that devices like ours will find an increasingly large market. Future directions might include customization by offering various designs, colors, and form factors could make the device appealing to a broader audience. It might also be incorporated into existing objects like jewelry or watches. Partnering with organizations, such as colleges or corporations, could see this device being provided as a standard safety tool for members or employees. Future iterations might use machine learning to better understand the context in which the "safe word" is activated, providing more nuanced support to the user.

I recently read an article on TechCrunch about Google's Project Abacus, which attempts to provide more secure authentication by using biometric data in place of passwords. This technology may have a significant impact on our work, particularly when it comes to making sure that only the device's owner may securely activate the "safe word" feature.

You can find the article here: [Google's Project Abacus](https://techcrunch.com/2016/05/23/google-plans-to-bring-password-free-logins-to-android-apps-by-year-end/)

## Week 6 (9/28 - 10/05)

My Photon2 was malfunctioning throughout the week, blinking all sorts of crazy colors, so I could barely follow the flashing instructions during class on Thursday but I was finally able to fix it (using the device doctor and something else which I don't remember now) after several attempts, on Monday. Now it is peacefully breathing cyan, as it should. We chose our Project 2 topics this week and joined teams - exciting. My team consists of 4 members (myself, Vidit, Liam and Eliza) and our topic is 'Breaking Language Barriers.'

Our motivation is simple: in today's global world, language is still a big hurdle in understanding each other. Many people face daily challenges, like tourists asking for directions or doctors understanding patients. Poor communication can lead to serious problems, including life-threatening situations. So, we aim to build a translation/transcription system that could make life easier for everyone - including but not limited to tourists, expats, linguaphiles, the hearing impaired, business people.

We're looking at different ways to use smart glasses. One idea is to help tourists understand foreign signs and menus. The smart glasses can instantly translate text you see, using augmented reality. They are clear and unobtrusive. We're also considering a wearable device that translates spoken conversations in real-time. This device focuses on audio but also has a display for reading the conversation if you can't hear it. Both aim to make it easier for people who speak different languages to communicate.

We're short on time, so we're focusing on making a basic prototype. It will show our main idea of real-time translation for what the user sees. We'll also make a digital design to help explain our product better. This way, we can fully share our idea even with limited time. I look forward to the coming weeks and our final prototype. Thank you and have a great day.

### Speculations

The SonicSight AR project is a groundbreaking initiative aimed at aiding the hearing-impaired by providing visual cues for auditory signals. Developed with machine learning algorithms, the device can recognize a variety of sounds—ranging from emergency sirens to casual conversations—and alert the user through a low-cost augmented reality (AR) display. This technology has the potential to revolutionize the way hearing-impaired individuals interact with their environment, making it safer and more accessible. This will be very useful in the future.

Link: [SonicSight AR - Sound Classification with Feedback on an Augmented Reality Display](https://edge-impulse.gitbook.io/experts/image-projects/particle-photon-2-sonicsight-ar)


## Week 5 (9/21 - 9/28)

Great week! I learned more about the Photon2 and sensors. I was able to connect the wires and flash my code to the device to make the LED lights blink :)

<img src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/e9d4645a-3a86-415f-8c4b-227ec88908e9" width="500" height="700" />


As there was no assignment this week, I don't have much to say. However, I'd like to discuss the guest lecture which was absolutely amazing. Adrian Freed seemed like a very creative and innovative person. I loved how he shared his work with us, both digitally and physically. I also enjoyed the brainstorming activity - maybe I'll talk more about that. I believe the class on Monday, this week, was a very productive session because I got to work in a team and generate innovative ideas - thrilling! My team's theme was "Energy" and we came up with a bunch of interesting ideas, working together. We thought of several use cases related to energy saving, from kids' education, households, companies, individuals, to energy visualization. We then defined the problem and came up with 5 possible solution, one from each team member. Mine was a platform teaching kids about energy saving through gamification. Others included mini art installations, interactive color-coded maps, etc.  

<img src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/10a2454c-d013-424c-9ca5-d92032a0d643" width="500" height="500" />

Back to the guest lecture with Adrian Freed. I also had fun building Stonehenge using the wooden tiles provided by the team. Here are is a photo of the activity:
| | |
|:-------------------------:|:-------------------------:|
![Stonehenge](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/2e15ca5b-1d68-47d1-ae9f-26057e49bf90) | ![High Tower](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/acadea2a-6894-4aca-921a-d2221ca78e18)

And here are some of the materials from Adrian Freed's most treasured possession (the binder of rare materials):

| | | |
|:-------------------------:|:-------------------------:|:-------------------------:|
![Magical Book of Materials 1](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/67428257-0ef3-4c53-8305-0cf42f936741) | ![Magical Book of Materials 2](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/9fd311b6-ce43-4f81-bc58-01747290fb85) | ![Magical Book of Materials 3](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/6d093965-7ea6-4de8-9a90-c37e0cb48ca1)

And finally, a photo of the lecture. It was the most fun TDF session yet:

<img src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/53bb4a29-1565-487d-90bd-c493868abf47" width="560" height="747" />

### Speculations:
Adrian's talk inspired me to look further into conductive materials. Working with conductive materials opens up a world of possibilities in various technological fields, from electronics to wearable devices and beyond. The integration of conductive materials into flexible and stretchable substrates seems very interesting. Imagine clothing and accessories that incorporate conductive threads or materials, allowing for seamless integration of electronic components into our daily wear. This could lead to clothing with embedded health-monitoring sensors, smart textiles, or even wearable displays. Additionally, the combination of conductive materials with AI technologies could result in smart environments that adapt to our preferences and needs. For instance, conductive materials integrated into the architecture of buildings could enable energy-efficient systems that learn from occupants' behavior. Also, advances in printable conductive inks and materials may lead to a future where electronic circuits and components can be printed directly onto surfaces, including paper, plastics, and even 3D-printed objects. This could democratize electronics manufacturing, enabling rapid prototyping and customization. So cool!


## Week 4 (9/14 - 9/21)

The main task for the week was to connect my Photon2 to the internet. Not as challenging as last week's task - or so I thought. I took my device out of the box,  connected it to the USB cable provided and plugged it into the USB port of my computer. Creating a Particle account was the easiest part, and then I had to setup my Photon2. My computer just wouldn't detect the device - I unplugged, reconnected, reset - nothing changed. The status light kept blinking blue, which meant it was in listening mode, so I knew the problem was not with the Photon2 but with my computer. After trying a different USB cable, I was able to connect my device properly. But then I got stuck in the next phase of the setup process - Update. 

![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/eb9e5ec3-0682-4411-80af-e7a5457d20fe)

![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/2d9791a5-4e77-47e2-9c4e-881203669a09)

![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/99daf8c9-95a3-44af-b2b4-583cf4810536)

Fast forward many hours, I was finally able to set it up correctly. I flashed the device using the Particle Device Doctor and then tried again. Since I was using Berkeley IoT in my home, I wasn't able to connect it to the wifi using that network because I needed the MAC address. So, I connected it to my mobile hotspot instead. It finally worked!!! I am so happy. Now my Photon2 is all set up and I'm ready to take on the next task for the week. Yayy!!

### Speculations:

After doing some research, I realized that Particle's Photon2 represents a significant step forward in the world of IoT (Internet of Things) development and connectivity. As we engage with this hardware platform, it's intriguing to contemplate its future trajectory. One possibility is that we'll see even more compact and power-efficient iterations of Photon2. The demand for smaller, longer-lasting IoT devices continues to grow, especially in applications like wearables and environmental monitoring. Future iterations may integrate advanced power management systems, further extending battery life and reducing the environmental impact. Another exciting prospect is the evolution of the Particle ecosystem. There might be more integrations of more sensors, AI capabilities, and machine learning libraries into the Particle platform, making it easier for developers to create intelligent and data-driven IoT solutions. This could lead to the development of predictive maintenance applications, where connected devices can anticipate and prevent failures in real-time. Pretty cool, isn't it? I'm glad we get to work with this amazing piece of technology. Can't wait to see what my cohort creates with the Photon2 this semester :)


## Week 3 (9/07 - 9/14)
What a week! This was by far the busiest week I've had this year, with all the Rhino/Grasshopper tutorials, presentations, readings, etc. This week, I learned so much about parametric design (I'm so proud of myself). I went from creating rectangles last week to generating some pretty cool parametric shapes (or we can call them "vases") using Grasshopper. Here are some of the models I created:

![Screenshot 2023-09-14 132624](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/959a0811-3a2a-4902-aabe-bdfa4174b8ee)

This one was sort of a failed early version that I created. Turns out there were so many things wrong with my code, which Cody was kind enough to take a look at, and helped me fix it. Yay!

These are the newer, improved versions of what I was trying to create:

![Screenshot 2023-09-14 132816](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/941485ec-febf-42d3-ad92-c8730f810a19)
![Screenshot 2023-09-14 132710](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/d12401e5-305d-4312-a496-838c53c5f362)
![Screenshot 2023-09-14 132655](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/f8a385ca-8dc2-4171-81bd-3ea9226bd796)

At first, I tried to join the model, which was a mesh, with the existing cellphone stand, a brep, to sort of create a combination of the two - it was supposed to be a cellphone stand with a mini vase popping out on top of it. But that was an epic fail - the conversion from brep to mesh really didn't work out. I even sought the assistance of Jeff, who was super helpful and tried to help me figure it out. I was SO CLOSE (probably not). For the sake of time, I decided to improve upon the model I created from scratch and finally let the cellphone stand go :(

Good news is, I was able to change the "vase" model from a constructed mesh to a brep, so now, I can join the vase with the cellphone stand dif I wish to, but I won't right now due to the time crunch. I can always try that again after the deadline. I'm glad to say I have achieved my goal - challenge completed! I declare this an axolotl-level challenge from which I have gloriously emerged victorious! ヾ(*´ ∇ `)ﾉ

I think the reason why I ended up with a "vase" model was because I had to create a vessel for my Studio Foundations class and I couldn't get it out of my head. I just had to. And it turned out nicely, so, yay.
So, to create this model, I began with a point, which I then turned into a line, which I then divided into several points (for flexibility). I added a range so I could adjust the number of points I had. Next was the circles, created from the points, connected to a seam and further divided into more points around each circle. Next, the pattern was generated using dispatch and weave, which created circles in the already existing circles, fed to a polyline component, lofted and capped. That's it! This took me the entire week (including the weekend) to create. Needless to say, I'm not disappointed. Last week, I felt quite intimidated when I saw the creations of my cohorts in class - they were so cool - and I thought I would never be able to, but now I can finally say I created something nice too!

Here's a link to my video: [Sara's YouTube Video](https://youtu.be/CBZZ2_-XeWc)

Here are shots of my Grasshopper file:
![Screenshot 2023-09-14 132935](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/fa3771b8-6956-45f1-a6b1-4a40f731e981)
![Screenshot 2023-09-14 132957](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/45020818-3c6f-4782-b4eb-d535f73fb4b1)
![Screenshot 2023-09-14 133019](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/8ad473ba-0c54-4473-86aa-37507eeeb6e0)
![Screenshot 2023-09-14 133035](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/d6c62b27-612e-4cde-ae1c-9062af8617fd)

### Speculations:
Our journey as a cohort in mastering 3D design tools is an ongoing process. While we've encountered challenges in understanding Rhino and Grasshopper, I believe perseverance will be our greatest asset. As we move forward, I consider exploring other complementary tools like Tinkercad, Blender, or even game engines like Unity, which are increasingly used for design visualization and interactivity. 

A groundbreaking development in the 3D printing world caught my attention recently. Researchers at MIT have made significant progress in 3D printing with glass. They've developed a 3D printer capable of creating intricate glass structures, which has potential applications in architecture, optics, and even electronics.

Here's a link to the article: [MIT's 3D Printing with Glass](https://www.ll.mit.edu/news/new-method-3d-prints-glass-low-temperatures)


## Week 2 (8/31 - 9/07)
This week, I spent a  lot of time on Rhino and Grasshopper trying to learn more and work through some topics with which I've been struggling. I found some courses on Linkedin Learning which I took and watched the videos throughout the weekend. Some insights were gained, some confusions were made. Nevertheless, I picked up some new tricks along the way. I know it's not much but II just want to say that I have been practicing and I'm now getting used to the concept of parametric design using grasshopper. After trying a bunch of different things, I've learned how many of the components work, how to navigate the interface, manipulate parameters and how to "bake." Yay :) 
![image](https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/410e8e93-71b5-40af-89a9-230be5b8b268)



## Week 1 (8/24 - 8/31)

This week has been very exciting for me - from learning how to use Rhino to printing my very first 3D model. At first, I was just going to re-create the 3D phone stand from class, but then I thought I could create my own instead. The plan was to design a 3D stand for dancers, with a mechanical revolving top that uses motion tracking technology, which would make it easier for dancers to record their dance routines. But obviously, I was getting ahead of myself because there was no way I'd be able to create something like that, given my current skill set and level, in such a short amount of time. Nevertheless, it's the thought that counts :)

| | |
|:-------------------------:|:-------------------------:|
|<img width="1604" alt="Week 1 - 3D Phone Case 2" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/d44daaf9-d85f-46c8-af93-25f5a9ec3b3b">  Week 1 Sketch |  <img width="1604" alt="Week 1 - 3D Phone Case 3" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/d518e9a9-be27-49ce-a5ae-660e5f7d6893"> Week 1 Product|

I made a rough sketch of what I wanted it to look like. Not as detailed as I'd hoped but right now I'm working on improving my sketching skills. I, then, took the measurements of my phone, allowing for some wiggle room around the phone holding area of the stand. I tried to desiign the ephone case directly in RHino and failed several times. After many attemps, I tried to design it in Fusion360 instead, where I found success on the second try. So, I took my learnings from the Fusion360 and applied them to my designs in Rhino. Little progress was made, but gradually, I think I got the hang of it. I spent numerous hours tinkering with the software before I was able to fully design the 3D phone stand, luckily. To be honest, if I were asked to redo the design exactly the same way in Rhino, I think I'd be lost. I'm still watchcing tutorials on how to use Rhino properly and don't even get me started on Grasshopper. I still can't wrap my head around it. But I won't stop trying. Someday, hopefully in the near future, I know I'll be able to effectively use Rhino to create whatever design I can dream of andd I can't wait for that day to come.

The rapid evolution of 3D design tools is both promising and challenging. In the near future, we can anticipate more accessible and user-friendly interfaces. Machine learning and AI integration might help streamline the design process, offering real-time suggestions and automation for intricate tasks like Grasshopper scripting. Additionally, cloud-based collaboration and real-time rendering capabilities could become standard features, making it easier for designers to work together seamlessly across the globe. The convergence of augmented reality (AR) and 3D modeling tools might also offer exciting opportunities for more immersive and interactive design experiences. In the coming weeks, I aspire to delve deeper into mastering Rhino and explore Grasshopper with determination. Grasshopper's visual programming paradigm may become less daunting with practice, and its potential for parametric design will probably unlock new creative dimensions for me. In the future, I hope to incorporate emerging technologies such as sensor fusion and gesture recognition, enabling my 3D phone stand to respond dynamically to the dancer's movements. This fusion of design and technology holds the potential to revolutionize the field of performance recording. Additionally, I will dedicate my time to improving my sketching skills. As I navigate the evolving landscape of 3D design, I shall embrace the challenges as opportunities for growth and innovation.

Recently, I came across an exciting development in the field of 3D design and manufacturing. Adidas, the renowned sportswear company, has unveiled a project called "Futurecraft.STRUNG." They have created a 3D-printed performance shoe upper using a new technique called "strung" which involves robotic threading of textile material to create intricate and customized designs. This not only showcases the capabilities of 3D printing but also highlights the potential for personalized, high-performance products in the sports industry. This innovation is inspiring as it demonstrates how 3D design and printing technologies are pushing the boundaries of what's possible in product design and manufacturing. It's a reminder of how the skills we are developing in this class can have a real impact on industries beyond just 3D modeling and can lead to groundbreaking advancements in various fields.

Here's a link to the article: [Adidas Futurecraft.STRUNG](https://www.adidas.com/us/blog/562694-our-new-textile-innovation-meet-futurecraftstrung).
And the video: [Watch Video](https://www.adidas.com/us/futurecraft)



### Photo Dump
| | | |
|:-------------------------:|:-------------------------:|:-------------------------:|
|<img width="1604" alt="Week 1 - 3D Phone Case 2" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/33216942-6914-42b9-a4df-5b15a26e1a56">  3D Phone Stand |  <img width="1604" alt="Week 1 - 3D Phone Case 3" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/f1e4456f-94dd-4166-86a6-ce596bea1a4d">|<img width="1604" alt="Week 1 - 3D Phone Case 4" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/5f7facc4-7232-4cf6-a5b9-08f5abab8be8">|
|<img width="1604" alt="Week 1 - 3D Phone Case 5" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/439ddc37-9327-4529-a08c-f0ea5c50aa1a">  |  <img width="1604" alt="Week 1 - 3D Phone Case 6" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/6834c7bd-a893-48bb-b706-a0a7d60afd6d">|<img width="1604" alt="Week 1 - 3D Phone Case 7" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/7c3dd215-9729-4852-9eb5-d94135806c65">|
|<img width="1604" alt="Week 1 - 3D Phone Case 8" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/2aa55156-d4de-48b0-9bc0-893de4101523">  |  <img width="1604" alt="Week 1 - 3D Phone Case 9" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/56972edf-62a0-472c-a02a-6ffc8704a72e">|<img width="1604" alt="Week 1 - 3D Phone Case 10" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/984b7c64-7723-4795-8454-fca6fd7f0098">|
|<img width="1604" alt="Week 1 - 3D Phone Case 11" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/ac412f58-6d87-49a4-8325-99e209a31079">  |  <img width="1604" alt="Week 1 - 3D Phone Case 12" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/1255193e-ab7c-47b7-a55f-ad9144ff7dd7">|<img width="1604" alt="Week 1 - 3D Phone Case 13" src="https://github.com/Berkeley-MDes/tdf-fa23-sarazaki/assets/143126838/da6de8bf-c6ef-43d6-847e-c070c16d9b69">|
